{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.round(Tensor([0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2, 14, 14])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3, 2],\n",
       "        [0, 7],\n",
       "        [0, 8],\n",
       "        [4, 8],\n",
       "        [6, 0]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000 # Number of data samples in training and test set\n",
    "\n",
    "train_input, train_target, train_classes, \\\n",
    "    test_input, test_target, test_classes = prologue.generate_pair_sets(N)\n",
    "\n",
    "print(train_input.shape)\n",
    "print(train_target.shape)\n",
    "print(train_classes.shape)\n",
    "\n",
    "train_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input, mean, std):\n",
    "    input.sub_(mean).div_(std)\n",
    "    \n",
    "def process_data(img_input, classes, one_hot_classes=False):\n",
    "    \n",
    "    n_img = img_input.size(0) \n",
    "    img_input_1 = img_input[:,0,:,:].reshape(n_img, 1, 14, 14)\n",
    "    img_input_2 = img_input[:,1,:,:].reshape(n_img, 1, 14, 14)\n",
    "    \n",
    "    img_classes_1 = prologue.convert_to_one_hot_labels(img_input_1, classes[:,0]) if one_hot_classes else classes[:,0]\n",
    "    img_classes_2 = prologue.convert_to_one_hot_labels(img_input_2, classes[:,1]) if one_hot_classes else classes[:,1]\n",
    "    \n",
    "    img_classes_1.reshape(-1,1)\n",
    "    img_classes_2.reshape(-1,1)\n",
    "    \n",
    "    return img_input_1, img_input_2, img_classes_1, img_classes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = train_input.mean(dim=(0,2,3), keepdim=True)\n",
    "std = train_input.std(dim=(0,2,3), keepdim=True)\n",
    "\n",
    "normalize(train_input, mean, std)\n",
    "normalize(test_input, mean, std)\n",
    "\n",
    "train_input_1, train_input_2, train_classes_1, train_classes_2 = process_data(train_input, train_classes)\n",
    "test_input_1, test_input_2, test_classes_1, test_classes_2 = process_data(test_input, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitNet(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(DigitNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompNet(torch.nn.Module):\n",
    "    def __init__(self, digitNet):\n",
    "        super(CompNet, self).__init__()\n",
    "        self.digitNet = digitNet\n",
    "        self.fc1 = nn.Linear(20, 50)\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 1)\n",
    "        \n",
    "    def forward(self, x1, x2,train=True):\n",
    "        x1 = self.digitNet.forward(x1)\n",
    "        x2 = self.digitNet.forward(x2)\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_digit, model_comp, \n",
    "                train_input_1, train_input_2, train_classes_1, train_classes_2, train_target, \n",
    "                criterion_digit=nn.CrossEntropyLoss(), criterion_comp=nn.BCELoss(), \n",
    "                mini_batch_size=25,nb_epochs=50, lr=1e-1):\n",
    "    \n",
    "    #optimizer_digit = torch.optim.SGD(model_digit.parameters(), lr=lr)\n",
    "    optimizer_comp = torch.optim.SGD(model_comp.parameters(), lr=lr)\n",
    "    \n",
    "    for e in range(nb_epochs):\n",
    "        if e % 5 == 0:\n",
    "            print(\"Epochs {}\".format(e))\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            \n",
    "            # digit classification \n",
    "            output_img_1 = model_digit(train_input_1.narrow(0, b, mini_batch_size))\n",
    "            output_img_2 = model_digit(train_input_2.narrow(0, b, mini_batch_size))\n",
    "            \n",
    "            loss_img_1 = criterion_digit(output_img_1, train_classes_1.narrow(0, b, mini_batch_size))\n",
    "            loss_img_2 = criterion_digit(output_img_2, train_classes_2.narrow(0, b, mini_batch_size))\n",
    "            loss_img = loss_img_1 + loss_img_2\n",
    "            \n",
    "            output_comp = model_comp(train_input_1.narrow(0, b, mini_batch_size), train_input_2.narrow(0, b, mini_batch_size))\n",
    "            batch_target = train_target.narrow(0, b, mini_batch_size).reshape(-1,1).float()\n",
    "            loss_comp = criterion_comp(output_comp, batch_target)\n",
    "            \n",
    "            loss = loss_img + loss_comp\n",
    "            \n",
    "            if b==0:\n",
    "                print(\"loss = {}, loss_img = {}, loss_comp = {}\".format(loss, loss_img, loss_comp))\n",
    "                \n",
    "            model_digit.zero_grad()\n",
    "            model_comp.zero_grad()\n",
    "            loss.backward()\n",
    "            #optimizer_digit.step()\n",
    "            optimizer_comp.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152326\n",
      "155977\n",
      "training...\n",
      "Epochs 0\n",
      "loss = 5.307267189025879, loss_img = 4.6141204833984375, loss_comp = 0.6931465864181519\n",
      "loss = 4.4057111740112305, loss_img = 3.712541103363037, loss_comp = 0.6931700706481934\n",
      "loss = 3.9772825241088867, loss_img = 3.282382011413574, loss_comp = 0.6949005126953125\n",
      "loss = 2.688941478729248, loss_img = 1.9946273565292358, loss_comp = 0.6943140625953674\n",
      "loss = 2.282613754272461, loss_img = 1.584642767906189, loss_comp = 0.6979708671569824\n",
      "Epochs 5\n",
      "loss = 1.8116049766540527, loss_img = 1.1196770668029785, loss_comp = 0.6919278502464294\n",
      "loss = 2.211294174194336, loss_img = 1.5174247026443481, loss_comp = 0.6938693523406982\n",
      "loss = 1.1094796657562256, loss_img = 0.4087395668029785, loss_comp = 0.7007400393486023\n",
      "loss = 1.0364018678665161, loss_img = 0.362297385931015, loss_comp = 0.6741044521331787\n",
      "loss = 0.9700140953063965, loss_img = 0.3032098710536957, loss_comp = 0.6668042540550232\n",
      "Epochs 10\n",
      "loss = 0.9607033133506775, loss_img = 0.27737879753112793, loss_comp = 0.6833245158195496\n",
      "loss = 0.9542549252510071, loss_img = 0.2624661326408386, loss_comp = 0.6917887926101685\n",
      "loss = 0.8721064329147339, loss_img = 0.23873193562030792, loss_comp = 0.6333745121955872\n",
      "loss = 0.8336458206176758, loss_img = 0.23413416743278503, loss_comp = 0.5995116233825684\n",
      "loss = 0.788557767868042, loss_img = 0.1741122007369995, loss_comp = 0.6144455671310425\n",
      "Epochs 15\n",
      "loss = 0.8435066938400269, loss_img = 0.16523081064224243, loss_comp = 0.6782758831977844\n",
      "loss = 0.7320560812950134, loss_img = 0.16969089210033417, loss_comp = 0.5623651742935181\n",
      "loss = 0.8055166006088257, loss_img = 0.14093905687332153, loss_comp = 0.6645775437355042\n",
      "loss = 0.685258686542511, loss_img = 0.10436251014471054, loss_comp = 0.5808961987495422\n",
      "loss = 0.6632794141769409, loss_img = 0.10774945467710495, loss_comp = 0.5555299520492554\n",
      "Epochs 20\n",
      "loss = 0.6866230368614197, loss_img = 0.09465587139129639, loss_comp = 0.5919671654701233\n",
      "loss = 0.6079027652740479, loss_img = 0.08868179470300674, loss_comp = 0.5192209482192993\n",
      "loss = 0.6132032871246338, loss_img = 0.07769127190113068, loss_comp = 0.5355120301246643\n",
      "loss = 0.6269081830978394, loss_img = 0.07521288096904755, loss_comp = 0.5516952872276306\n",
      "loss = 0.6592451333999634, loss_img = 0.06921897828578949, loss_comp = 0.5900261402130127\n",
      "Epochs 25\n",
      "loss = 0.639539361000061, loss_img = 0.06002066656947136, loss_comp = 0.5795186758041382\n",
      "loss = 0.5862923860549927, loss_img = 0.059999238699674606, loss_comp = 0.526293158531189\n",
      "loss = 0.5539103746414185, loss_img = 0.055867068469524384, loss_comp = 0.4980432987213135\n",
      "loss = 0.560920238494873, loss_img = 0.05487438291311264, loss_comp = 0.5060458779335022\n",
      "loss = 0.5824275016784668, loss_img = 0.04806870222091675, loss_comp = 0.53435879945755\n",
      "Epochs 30\n",
      "loss = 0.5645015835762024, loss_img = 0.046504177153110504, loss_comp = 0.5179973840713501\n",
      "loss = 0.5697606801986694, loss_img = 0.041175514459609985, loss_comp = 0.5285851955413818\n",
      "loss = 0.5613207817077637, loss_img = 0.0375831201672554, loss_comp = 0.5237376689910889\n",
      "loss = 0.5557655692100525, loss_img = 0.03130478411912918, loss_comp = 0.5244607925415039\n",
      "loss = 0.5690692067146301, loss_img = 0.03046259470283985, loss_comp = 0.538606584072113\n",
      "Epochs 35\n",
      "loss = 0.523975133895874, loss_img = 0.036589376628398895, loss_comp = 0.48738574981689453\n",
      "loss = 0.5446485280990601, loss_img = 0.03193056955933571, loss_comp = 0.5127179622650146\n",
      "loss = 4.162929058074951, loss_img = 3.482635498046875, loss_comp = 0.6802935004234314\n",
      "loss = 2.832913875579834, loss_img = 2.229701519012451, loss_comp = 0.6032124161720276\n",
      "loss = 2.579324245452881, loss_img = 1.9332391023635864, loss_comp = 0.6460850238800049\n",
      "Epochs 40\n",
      "loss = 1.5221800804138184, loss_img = 0.9366792440414429, loss_comp = 0.5855008363723755\n",
      "loss = 0.918094277381897, loss_img = 0.3808950185775757, loss_comp = 0.5371992588043213\n",
      "loss = 0.8440392017364502, loss_img = 0.2945077419281006, loss_comp = 0.5495314598083496\n",
      "loss = 0.8670046329498291, loss_img = 0.32196131348609924, loss_comp = 0.5450432896614075\n",
      "loss = 0.7331424951553345, loss_img = 0.2213013768196106, loss_comp = 0.5118411183357239\n",
      "Epochs 45\n",
      "loss = 0.6786538362503052, loss_img = 0.1555352807044983, loss_comp = 0.5231185555458069\n",
      "loss = 0.6676349639892578, loss_img = 0.15572385489940643, loss_comp = 0.5119110941886902\n",
      "loss = 0.6159183382987976, loss_img = 0.12204558402299881, loss_comp = 0.493872731924057\n",
      "loss = 0.6058375835418701, loss_img = 0.12085966765880585, loss_comp = 0.4849779009819031\n",
      "loss = 0.581631064414978, loss_img = 0.11471825838088989, loss_comp = 0.46691280603408813\n",
      "Epochs 50\n",
      "loss = 0.5827620625495911, loss_img = 0.09403537213802338, loss_comp = 0.4887267053127289\n",
      "loss = 0.5786672234535217, loss_img = 0.08396650105714798, loss_comp = 0.49470072984695435\n",
      "loss = 0.569892942905426, loss_img = 0.08173686265945435, loss_comp = 0.4881560802459717\n",
      "loss = 0.573958694934845, loss_img = 0.07467381656169891, loss_comp = 0.49928486347198486\n",
      "loss = 0.5671901702880859, loss_img = 0.06613951921463013, loss_comp = 0.5010506510734558\n",
      "Epochs 55\n",
      "loss = 0.5396850109100342, loss_img = 0.05957914888858795, loss_comp = 0.48010584712028503\n",
      "loss = 0.5185340046882629, loss_img = 0.05490841343998909, loss_comp = 0.46362560987472534\n",
      "loss = 0.5028752684593201, loss_img = 0.056720759719610214, loss_comp = 0.44615450501441956\n",
      "loss = 0.5510143637657166, loss_img = 0.0446745790541172, loss_comp = 0.5063397884368896\n",
      "loss = 0.4897996187210083, loss_img = 0.03877328336238861, loss_comp = 0.4510263502597809\n",
      "Epochs 60\n",
      "loss = 0.4987508952617645, loss_img = 0.03595564141869545, loss_comp = 0.4627952575683594\n",
      "loss = 0.4664352536201477, loss_img = 0.0370284803211689, loss_comp = 0.4294067621231079\n",
      "loss = 0.4943840801715851, loss_img = 0.04281620308756828, loss_comp = 0.4515678882598877\n",
      "loss = 0.4808104634284973, loss_img = 0.03035668283700943, loss_comp = 0.4504537880420685\n",
      "loss = 0.4631081223487854, loss_img = 0.0291505828499794, loss_comp = 0.4339575469493866\n",
      "Epochs 65\n",
      "loss = 0.460826575756073, loss_img = 0.02674519456923008, loss_comp = 0.43408137559890747\n",
      "loss = 0.45630908012390137, loss_img = 0.021444374695420265, loss_comp = 0.43486469984054565\n",
      "loss = 0.4677252769470215, loss_img = 0.024310899898409843, loss_comp = 0.4434143900871277\n",
      "loss = 0.44978055357933044, loss_img = 0.017368489876389503, loss_comp = 0.4324120581150055\n",
      "loss = 0.4857235550880432, loss_img = 0.018643999472260475, loss_comp = 0.4670795500278473\n",
      "Epochs 70\n",
      "loss = 0.4500311315059662, loss_img = 0.016383619979023933, loss_comp = 0.4336475133895874\n",
      "loss = 0.454354852437973, loss_img = 0.016204265877604485, loss_comp = 0.4381505846977234\n",
      "loss = 0.43947410583496094, loss_img = 0.015803083777427673, loss_comp = 0.42367100715637207\n",
      "loss = 0.43719664216041565, loss_img = 0.013314533047378063, loss_comp = 0.4238820970058441\n",
      "loss = 0.43808311223983765, loss_img = 0.016323765739798546, loss_comp = 0.42175933718681335\n",
      "Epochs 75\n",
      "loss = 0.4324043095111847, loss_img = 0.015250246971845627, loss_comp = 0.41715407371520996\n",
      "loss = 0.4304879903793335, loss_img = 0.013337526470422745, loss_comp = 0.41715046763420105\n",
      "loss = 0.43081218004226685, loss_img = 0.012341813184320927, loss_comp = 0.4184703528881073\n",
      "loss = 0.45048677921295166, loss_img = 0.011516779661178589, loss_comp = 0.43896999955177307\n",
      "loss = 0.4288877844810486, loss_img = 0.011619437485933304, loss_comp = 0.4172683358192444\n",
      "Epochs 80\n",
      "loss = 0.4675956070423126, loss_img = 0.009160097688436508, loss_comp = 0.4584355056285858\n",
      "loss = 0.42901095747947693, loss_img = 0.011654098518192768, loss_comp = 0.41735684871673584\n",
      "loss = 0.4183901846408844, loss_img = 0.012305863201618195, loss_comp = 0.4060843288898468\n",
      "loss = 0.41919422149658203, loss_img = 0.008412377908825874, loss_comp = 0.4107818305492401\n",
      "loss = 0.41594329476356506, loss_img = 0.008770124055445194, loss_comp = 0.40717315673828125\n",
      "Epochs 85\n",
      "loss = 0.44262197613716125, loss_img = 0.00946258194744587, loss_comp = 0.43315938115119934\n",
      "loss = 0.42210039496421814, loss_img = 0.00909932516515255, loss_comp = 0.41300106048583984\n",
      "loss = 0.43711745738983154, loss_img = 0.008548805490136147, loss_comp = 0.42856866121292114\n",
      "loss = 0.4124089777469635, loss_img = 0.008514448069036007, loss_comp = 0.4038945436477661\n",
      "loss = 0.4201512336730957, loss_img = 0.007584641687572002, loss_comp = 0.412566602230072\n",
      "Epochs 90\n",
      "loss = 0.4065397083759308, loss_img = 0.0074801137670874596, loss_comp = 0.39905959367752075\n",
      "loss = 0.4217672049999237, loss_img = 0.008340626955032349, loss_comp = 0.41342657804489136\n",
      "loss = 0.4234386682510376, loss_img = 0.006760131102055311, loss_comp = 0.4166785478591919\n",
      "loss = 0.4053395986557007, loss_img = 0.006294146180152893, loss_comp = 0.3990454375743866\n",
      "loss = 0.4067770838737488, loss_img = 0.0054939426481723785, loss_comp = 0.4012831449508667\n",
      "Epochs 95\n",
      "loss = 0.43702852725982666, loss_img = 0.006068838760256767, loss_comp = 0.43095970153808594\n",
      "loss = 0.43168729543685913, loss_img = 0.006530392915010452, loss_comp = 0.4251568913459778\n",
      "loss = 0.4442538022994995, loss_img = 0.008327113464474678, loss_comp = 0.4359266757965088\n",
      "loss = 0.4032071530818939, loss_img = 0.006452897563576698, loss_comp = 0.39675426483154297\n",
      "loss = 3.0773417949676514, loss_img = 2.511986255645752, loss_comp = 0.5653555393218994\n",
      "Epochs 100\n",
      "loss = 1.572684407234192, loss_img = 1.0812691450119019, loss_comp = 0.49141526222229004\n",
      "loss = 0.9083417057991028, loss_img = 0.43141913414001465, loss_comp = 0.47692257165908813\n",
      "loss = 0.9330525398254395, loss_img = 0.4461199641227722, loss_comp = 0.48693257570266724\n",
      "loss = 0.7120834589004517, loss_img = 0.24439147114753723, loss_comp = 0.4676920175552368\n",
      "loss = 0.6251171827316284, loss_img = 0.17321300506591797, loss_comp = 0.45190414786338806\n",
      "Epochs 105\n",
      "loss = 0.5906198024749756, loss_img = 0.1442706286907196, loss_comp = 0.446349173784256\n",
      "loss = 0.6067276000976562, loss_img = 0.13999080657958984, loss_comp = 0.4667368233203888\n",
      "loss = 0.5733854174613953, loss_img = 0.11477647721767426, loss_comp = 0.4586089253425598\n",
      "loss = 0.5435786247253418, loss_img = 0.12007635831832886, loss_comp = 0.42350223660469055\n",
      "loss = 0.530110239982605, loss_img = 0.10165828466415405, loss_comp = 0.4284519553184509\n",
      "Epochs 110\n",
      "loss = 0.512370765209198, loss_img = 0.0922292023897171, loss_comp = 0.4201415777206421\n",
      "loss = 0.518807053565979, loss_img = 0.07753444463014603, loss_comp = 0.4412726163864136\n",
      "loss = 0.49442946910858154, loss_img = 0.08016665279865265, loss_comp = 0.4142628014087677\n",
      "loss = 0.4948030710220337, loss_img = 0.06477567553520203, loss_comp = 0.43002739548683167\n",
      "loss = 0.47814154624938965, loss_img = 0.05592787265777588, loss_comp = 0.42221367359161377\n",
      "Epochs 115\n",
      "loss = 0.47896450757980347, loss_img = 0.05047681927680969, loss_comp = 0.4284876883029938\n",
      "loss = 0.473300576210022, loss_img = 0.04424380511045456, loss_comp = 0.4290567636489868\n",
      "loss = 0.44616785645484924, loss_img = 0.03665761277079582, loss_comp = 0.4095102548599243\n",
      "loss = 0.45680928230285645, loss_img = 0.03578381612896919, loss_comp = 0.42102545499801636\n",
      "loss = 0.43990910053253174, loss_img = 0.031012803316116333, loss_comp = 0.4088962972164154\n",
      "Epochs 120\n",
      "loss = 0.4515560567378998, loss_img = 0.02790459245443344, loss_comp = 0.42365145683288574\n",
      "loss = 0.4564127027988434, loss_img = 0.025218643248081207, loss_comp = 0.4311940670013428\n",
      "loss = 0.43896201252937317, loss_img = 0.020753026008605957, loss_comp = 0.4182089865207672\n",
      "loss = 0.4490821957588196, loss_img = 0.025221463292837143, loss_comp = 0.42386072874069214\n",
      "loss = 0.5519986748695374, loss_img = 0.026806414127349854, loss_comp = 0.5251922607421875\n",
      "Epochs 125\n",
      "loss = 0.5974274277687073, loss_img = 0.13105900585651398, loss_comp = 0.4663684070110321\n",
      "loss = 0.49729645252227783, loss_img = 0.07356615364551544, loss_comp = 0.4237302839756012\n",
      "loss = 0.4631308317184448, loss_img = 0.04662805050611496, loss_comp = 0.41650277376174927\n",
      "loss = 0.45030564069747925, loss_img = 0.03657042607665062, loss_comp = 0.41373521089553833\n",
      "loss = 0.4581524431705475, loss_img = 0.029465429484844208, loss_comp = 0.4286870062351227\n",
      "Epochs 130\n",
      "loss = 0.43438205122947693, loss_img = 0.025611378252506256, loss_comp = 0.40877068042755127\n",
      "loss = 0.4904881417751312, loss_img = 0.03032475709915161, loss_comp = 0.4601633846759796\n",
      "loss = 0.42699599266052246, loss_img = 0.021737374365329742, loss_comp = 0.4052586257457733\n",
      "loss = 0.4271887242794037, loss_img = 0.021754387766122818, loss_comp = 0.40543434023857117\n",
      "loss = 0.4185370206832886, loss_img = 0.01589501090347767, loss_comp = 0.40264201164245605\n",
      "Epochs 135\n",
      "loss = 0.41214072704315186, loss_img = 0.015284508466720581, loss_comp = 0.3968562185764313\n",
      "loss = 0.42076513171195984, loss_img = 0.014044415205717087, loss_comp = 0.40672072768211365\n",
      "loss = 0.4319854974746704, loss_img = 0.011461470276117325, loss_comp = 0.4205240309238434\n",
      "loss = 0.41501951217651367, loss_img = 0.010120516642928123, loss_comp = 0.404899001121521\n",
      "loss = 0.4139220416545868, loss_img = 0.00940625462681055, loss_comp = 0.4045157730579376\n",
      "Epochs 140\n",
      "loss = 0.4284992218017578, loss_img = 0.008715322241187096, loss_comp = 0.41978389024734497\n",
      "loss = 0.41447535157203674, loss_img = 0.010364195331931114, loss_comp = 0.4041111469268799\n",
      "loss = 0.4169631600379944, loss_img = 0.008080865256488323, loss_comp = 0.4088822901248932\n",
      "loss = 0.4144756495952606, loss_img = 0.0066421013325452805, loss_comp = 0.4078335464000702\n",
      "loss = 0.41289693117141724, loss_img = 0.006736133247613907, loss_comp = 0.40616080164909363\n",
      "Epochs 145\n",
      "loss = 0.41244378685951233, loss_img = 0.006968833040446043, loss_comp = 0.4054749608039856\n",
      "loss = 0.4425071179866791, loss_img = 0.00772128626704216, loss_comp = 0.4347858428955078\n",
      "loss = 0.4100903272628784, loss_img = 0.007124511990696192, loss_comp = 0.40296581387519836\n",
      "loss = 0.40356314182281494, loss_img = 0.006391970440745354, loss_comp = 0.39717116951942444\n",
      "loss = 0.41796261072158813, loss_img = 0.006329272408038378, loss_comp = 0.41163334250450134\n"
     ]
    }
   ],
   "source": [
    "model_digit = DigitNet(500)\n",
    "model_comp = CompNet(model_digit)\n",
    "\n",
    "print(sum(p.numel() for p in model_digit.parameters() if p.requires_grad))\n",
    "print(sum(p.numel() for p in model_comp.parameters() if p.requires_grad))\n",
    "print(\"training...\")\n",
    "\n",
    "train_model(model_digit=model_digit, model_comp=model_comp,\n",
    "            train_input_1=train_input_1, train_input_2=train_input_2,\n",
    "            train_classes_1=train_classes_1, train_classes_2=train_classes_2, \n",
    "            train_target=train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors_siamese(model_digit, model_comp,\n",
    "                              data_input_1, data_input_2, data_target, mini_batch_size=25):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for b in range(0, data_input_1.size(0), mini_batch_size):\n",
    "        #output_img_1 = model_digit(data_input_1.narrow(0, b, mini_batch_size))\n",
    "        #output_img_2 = model_digit(data_input_2.narrow(0, b, mini_batch_size))\n",
    "        \n",
    "        output_comp = model_comp(data_input_1.narrow(0, b, mini_batch_size), data_input_2.narrow(0, b, mini_batch_size),train=False)\n",
    "        output_comp = torch.round(output_comp)\n",
    "    \n",
    "        for k in range(mini_batch_size):\n",
    "            if data_target[b + k] != output_comp[k]:\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_error_siamese(model_digit, model_comp, tr_input_1, tr_input_2, tr_target, te_input_1, te_input_2, te_target):\n",
    "    print('train_error {:.02f}% test_error {:.02f}%'.format(\n",
    "                compute_nb_errors_siamese(model_digit, model_comp, tr_input_1, tr_input_2, tr_target) / N * 100,\n",
    "                compute_nb_errors_siamese(model_digit, model_comp, te_input_1, te_input_2, te_target) / N * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error 3.10% test_error 10.30%\n"
     ]
    }
   ],
   "source": [
    "print_error_siamese(model_digit, model_comp, train_input_1, train_input_2, train_target, test_input_1, test_input_2, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
